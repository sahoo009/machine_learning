{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a4e8b866",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q imageio\n",
    "!pip install -q opencv-python\n",
    "!pip install -q git+https://github.com/tensorflow/docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a65f45f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow_hub\n",
      "  Using cached tensorflow_hub-0.12.0-py2.py3-none-any.whl (108 kB)\n",
      "Requirement already satisfied: numpy>=1.12.0 in /home/sahoo009/anaconda3/envs/interview_prep/lib/python3.9/site-packages (from tensorflow_hub) (1.21.2)\n",
      "Requirement already satisfied: protobuf>=3.8.0 in /home/sahoo009/anaconda3/envs/interview_prep/lib/python3.9/site-packages (from tensorflow_hub) (3.17.2)\n",
      "Requirement already satisfied: six>=1.9 in /home/sahoo009/anaconda3/envs/interview_prep/lib/python3.9/site-packages (from protobuf>=3.8.0->tensorflow_hub) (1.16.0)\n",
      "Installing collected packages: tensorflow-hub\n",
      "Successfully installed tensorflow-hub-0.12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorflow_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2f3b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from absl import logging\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow_docs.vis import embed\n",
    "\n",
    "logging.set_verbosity(logging.ERROR)\n",
    "\n",
    "# some modules to help with reading the UCF101 dataset.\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import tempfile\n",
    "import ssl\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# some modules to display an animation using imageio.\n",
    "import imageio\n",
    "from IPython import display\n",
    "\n",
    "from urllib import request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "8a2ed5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities to fetch videos from UCF101 dataset\n",
    "UCF_ROOT = 'https://www.crcv.ucf.edu/THUMOS14/UCF101/UCF101/'\n",
    "_VIDEO_LIST = None\n",
    "_CACHE_DIR = tempfile.mkdtemp()\n",
    "unverified_context = ssl._create_unverified_context()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "273276a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 labels.\n"
     ]
    }
   ],
   "source": [
    "# get the kinetics-400 action labels from the GitHub repository.\n",
    "KINETICS_URL = 'https://raw.githubusercontent.com/deepmind/kinetics-i3d/master/data/label_map.txt'\n",
    "\n",
    "with request.urlopen(KINETICS_URL) as obj:\n",
    "    labels = [line.decode(\"utf-8\").strip() for line in obj.readlines()]\n",
    "\n",
    "print('Found %d labels.' % len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d703c9c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_ucf_videos():\n",
    "    \n",
    "    \"\"\"Lists videos available in UCF101 dataset.\"\"\"\n",
    "    global _VIDEO_LIST\n",
    "    if not _VIDEO_LIST:\n",
    "        index = request.urlopen(UCF_ROOT, context=unverified_context).read().decode('utf-8')\n",
    "        videos = re.findall('(v_[\\w_]+\\.avi)', index)\n",
    "        _VIDEO_LIST = sorted(set(videos))\n",
    "    \n",
    "    return list(_VIDEO_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "406d6618",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_ucf_video(video):\n",
    "    \"\"\"Fetchs a video and cache into local filesystem.\"\"\"\n",
    "    cache_path = os.path.join(_CACHE_DIR, video)\n",
    "    if not os.path.exists(cache_path):\n",
    "        urlpath = request.urljoin(UCF_ROOT, video)\n",
    "        print('Fetching %s => %s' % (urlpath, cache_path))\n",
    "        data = request.urlopen(urlpath, context=unverified_context).read()\n",
    "        open(cache_path, 'wb').write(data)\n",
    "    return cache_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2ca4ce09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities to open video files using CV2\n",
    "def crop_center_square(frame):\n",
    "    y, x = frame.shape[0:2]\n",
    "    min_dim = min(y, x)\n",
    "    start_x = (x // 2) - (min_dim // 2)\n",
    "    start_y = (y // 2) - (min_dim // 2)\n",
    "    return frame[start_y:(start_y + min_dim), start_x: (start_x + min_dim)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "77e87efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_video(path, max_frames=0, resize=(224, 224)):\n",
    "    \n",
    "    cap = cv2.VideoCapture(path)\n",
    "    frames = []\n",
    "    try:\n",
    "        while True:\n",
    "            ret, frame = cap.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = crop_center_square(frame)\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame[:, :, [2, 1, 0]]\n",
    "            frames.append(frame)\n",
    "      \n",
    "            if len(frames) == max_frames:\n",
    "                break\n",
    "    finally:\n",
    "        cap.release()\n",
    "    \n",
    "    return np.array(frames) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "966f0e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_gif(images):\n",
    "    \n",
    "    converted_images = np.clip(images * 255, 0, 255).astype(np.uint8)\n",
    "    imageio.mimsave('./animation.gif', converted_images, fps=25)\n",
    "    \n",
    "    embed.embed_file('./animation.gif')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5495e3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_ucf_videos():\n",
    "    \n",
    "    ucf_videos = list_ucf_videos()\n",
    "  \n",
    "    categories = {}\n",
    "    for video in ucf_videos:\n",
    "        category = video[2:-12]\n",
    "        if category not in categories:\n",
    "            categories[category] = []\n",
    "        categories[category].append(video)\n",
    "\n",
    "    print('Found %d videos in %d categories.' % (len(ucf_videos), len(categories)))\n",
    "\n",
    "    #for category, sequences in categories.items():\n",
    "    #    summary = \", \".join(sequences[:2])\n",
    "    #    print(\"%-20s %4d videos (%s, ...)\" % (category, len(sequences), summary))\n",
    "    \n",
    "    return categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "0bacefb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_sample_videos():\n",
    "    \n",
    "    videos = ['v_SoccerPenalty_g01_c02.avi', 'v_CricketShot_g04_c02.avi', \n",
    "              'v_PlayingGuitar_g01_c02.avi', 'v_HorseRace_g01_c01.avi']\n",
    "    \n",
    "    sample_videos = []\n",
    "    for video in videos:\n",
    "        video_path = fetch_ucf_video(video)\n",
    "        sample_video = load_video(video_path)\n",
    "        sample_videos.append(sample_video)\n",
    "    \n",
    "    #print(sample_videos.shape)\n",
    "    \n",
    "    return videos, sample_videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3356a6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model():\n",
    "\n",
    "    i3d = hub.load('https://tfhub.dev/deepmind/i3d-kinetics-400/1').signatures['default']\n",
    "    return i3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62fc3942",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model, video_name, sample_video):\n",
    "  \n",
    "    # Add a batch axis to the sample video.\n",
    "    model_input = tf.constant(sample_video, dtype=tf.float32)[tf.newaxis, ...]\n",
    "\n",
    "    logits = model(model_input)['default'][0]\n",
    "    probabilities = tf.nn.softmax(logits)\n",
    "\n",
    "    print('Top 5 actions for {}:'.format(video_name))\n",
    "    for i in np.argsort(probabilities)[::-1][:5]:\n",
    "        print(f'  {labels[i]:22}: {probabilities[i] * 100:5.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2533bff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \n",
    "    categorize_ucf_videos()\n",
    "    videos, sample_videos = load_sample_videos()\n",
    "    i3d = load_model()\n",
    "    \n",
    "    for index, sample_video in enumerate(sample_videos):\n",
    "        to_gif(sample_video)\n",
    "        predict(i3d, videos[index], sample_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "93af8a36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13320 videos in 101 categories.\n",
      "Top 5 actions for v_SoccerPenalty_g01_c02.avi:\n",
      "  shooting goal (soccer): 69.46%\n",
      "  marching              : 14.34%\n",
      "  kicking field goal    :  4.03%\n",
      "  playing tennis        :  3.56%\n",
      "  passing American football (in game):  2.60%\n",
      "Top 5 actions for v_CricketShot_g04_c02.avi:\n",
      "  playing cricket       : 97.77%\n",
      "  skateboarding         :  0.71%\n",
      "  robot dancing         :  0.56%\n",
      "  roller skating        :  0.56%\n",
      "  golf putting          :  0.13%\n",
      "Top 5 actions for v_PlayingGuitar_g01_c02.avi:\n",
      "  playing guitar        : 89.51%\n",
      "  strumming guitar      :  9.17%\n",
      "  busking               :  0.35%\n",
      "  playing drums         :  0.28%\n",
      "  recording music       :  0.23%\n",
      "Top 5 actions for v_HorseRace_g01_c01.avi:\n",
      "  marching              : 88.00%\n",
      "  shaking hands         :  1.98%\n",
      "  shredding paper       :  1.49%\n",
      "  driving car           :  1.18%\n",
      "  kicking field goal    :  1.02%\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d88a8b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
